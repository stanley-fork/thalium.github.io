<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=author content><meta name=description content="Thalium blog."><meta name=keywords content="blog,tech"><meta name=viewport content="width=device-width,minimum-scale=1,initial-scale=1"><meta name=generator content="Hugo 0.145.0"><link rel=canonical href=/posts/linux-kernel-rust-module-for-rootkit-detection/><meta property="og:url" content="/posts/linux-kernel-rust-module-for-rootkit-detection/"><meta property="og:site_name" content="THALIUM"><meta property="og:title" content="Linux kernel Rust module for rootkit detection"><meta property="og:description" content="The introduction of Rust into the Linux kernel allows to write kernel drivers in Rust, which we can use to build a kernel-level EDR. This post explores this possibility by designing various checks to detect kernel-level rootkits and implementing them using the kernel’s Rust API. We then discuss the experience of developing in Rust within the Linux kernel."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-12T08:00:00+00:00"><meta property="article:modified_time" content="2025-03-12T08:00:00+00:00"><meta property="article:tag" content="Linux"><meta property="article:tag" content="Kernel"><meta property="article:tag" content="Malware"><meta property="article:tag" content="Rust"><meta name=twitter:card content="summary"><meta name=twitter:title content="Linux kernel Rust module for rootkit detection"><meta name=twitter:description content="The introduction of Rust into the Linux kernel allows to write kernel drivers in Rust, which we can use to build a kernel-level EDR. This post explores this possibility by designing various checks to detect kernel-level rootkits and implementing them using the kernel’s Rust API. We then discuss the experience of developing in Rust within the Linux kernel."><meta itemprop=name content="Linux kernel Rust module for rootkit detection"><meta itemprop=description content="The introduction of Rust into the Linux kernel allows to write kernel drivers in Rust, which we can use to build a kernel-level EDR. This post explores this possibility by designing various checks to detect kernel-level rootkits and implementing them using the kernel’s Rust API. We then discuss the experience of developing in Rust within the Linux kernel."><meta itemprop=datePublished content="2025-03-12T08:00:00+00:00"><meta itemprop=dateModified content="2025-03-12T08:00:00+00:00"><meta itemprop=wordCount content="4262"><meta itemprop=keywords content="Linux,Kernel,Malware,Rust"><link rel=stylesheet href=/css/layout.css><link rel=stylesheet href=/css/default-dark.css><link rel=icon href=/favicon.ico><title>Linux kernel Rust module for rootkit detection
</title><script>MathJax={tex:{inlineMath:[["∳","∳"]],displayMath:[["∳∳","∳∳"]],processEscapes:!0},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script></head><body><div class=main><header><div class=header-bar><nav><div class=siteTitle><a href=/><img src=/shard_only_no_background.png></img>
<span>THALIUM</span></a></div><div class=nav-item-title><a class=nav-item href=/posts/>Posts</a></div><div class=nav-item-title><a class=nav-item href=/joinus/>Join Us</a></div><div class=nav-item-title><a class=nav-item href=/about/>About</a></div></nav></div></header><article class=post><h1 class=title>Linux kernel Rust module for rootkit detection</h1><div class=content><p>This work was part of an <strong>internship</strong> at Thalium on the subject of kernel-level malware detection in Rust on Linux.</p><p>Source code related to this article can be found in the following repositories:</p><ul><li><a href=https://github.com/thalium/rkchk-linux-next>Linux-next branch with some custom patches</a></li><li><a href=https://github.com/thalium/rkchk>Rust Linux Kernel Module designed for LKM rootkit detection</a></li></ul><h1 id=context>Context</h1><p>Linux systems are used in a wide variety of environments, from IoT to security critical servers. Therefore, they are a common target for attackers and there is a need for malware detection on those systems.</p><p>We can identify two distinct uses of such detection:</p><ul><li>Monitoring purposes: The goal is to detect the infection as soon as possible, ideally with an immediate response. This is commonly referred to as EDR (<em>Endpoint Detection and Response</em>).</li><li>Forensic purposes: The goal in this case is to gather as much relevant information as possible <em>post mortem</em> (i.e. after the infection has occured), to understand what happened and how.</li></ul><p>There is a vast variety of malware, which makes the task of detecting all of them quite extensive and unrealistic to accomplish within a 6-month internship.</p><p>Nevertheless, attackers often follow a common pattern when compromising a vulnerable machine, be it to install a keylogger, deploy a botnet worker, or gain access to data: they want to keep a persistent and reproducible access to the system.</p><p>This persistent access is typically obtained by using a type of malware called a <strong>rootkit</strong>. Detecting rootkits can be an efficient and generic way to determine that a system has been compromised. Hence, this article is dedicated to <strong>rootkit detection</strong>.</p><p>As stated in a 2024 paper by <a href=https://dl.acm.org/doi/10.1145/3688808>Jacob Stühn et al.</a>, there is a need for more modern rootkit detection software for Linux, as the existing open-source tools are quite old and less performant.</p><blockquote><p>In the following, I will mostly focus on the detection of <strong>kernel rootkits</strong>, which I find the most interesting. However, the developed tool integrates detection techniques for other types of rootkits (namely user space and eBPF rootkits).</p></blockquote><h2 id=rootkit-capabilities>Rootkit capabilities</h2><p>A rootkit commonly offers the following capabilities (extracted from the open-source <a href=https://github.com/f0rb1dd3n/Reptile>Reptile</a> rootkit&rsquo;s features):</p><ul><li><strong>Hiding itself</strong>: the rootkit shouldn&rsquo;t be detectable by a system administrator</li><li><strong>Hiding data</strong>: whether it is a part of a file&rsquo;s contents, an entire file, or a process, this capability is useful to hide other malwares</li><li><strong>Reverse root shell</strong>: often paired with connection-hiding capabilities (such that open ports are invisible, or that network monitoring tools do not show any traffic)</li><li><strong>Boot persistence</strong></li></ul><p>Now that we understand our target, let&rsquo;s learn about the tools we will use.</p><h1 id=how-the-linux-kernel-api-helps-us-for-malware-detection>How the Linux kernel API helps us for malware detection</h1><p>An intuitive approach is that the higher the privilege level of our EDR, the harder it becomes for malware to bypass it, and the more capabilities we will have to observe malware behavior and take action. This is why it is beneficial to place our EDR in the kernel.</p><blockquote><p>We can note that kernel-level rootkits have the same privilege level as us, so a kernel rootkit that is conscious of our tool can bypass it, and all we can hope is just to make its life harder.</p><p>A solution to this problem is to develop at hypervisor level — but even then, there exist hypervisor-level rootkits (e.g. <a href=https://en.wikipedia.org/wiki/Blue_Pill_%28software%29>Blue Pill</a>) and UEFI-level rootkits (e.g. <a href="https://h20195.www2.hp.com/v2/GetDocument.aspx?docname=4AA7-4019ENW">LoJax</a>).</p></blockquote><h2 id=running-code-in-the-linux-kernel>Running code in the Linux kernel</h2><p>As most kernels, Linux offers the possibility to dynamically load code in the kernel. This interface is called <strong>loadable kernel modules</strong> (or <strong>LKM</strong>) and is most often used to dynamically load drivers for hardware, although it can be used to develop detection tools.</p><p>The classic way to develop a LKM is in C, using the API exposed by the kernel which can be found, for the most part, in the <code>include/</code> folder of the source. Its documentation can be found <a href=https://docs.kernel.org/>here</a>. However, as developing in the kernel is most of the time a RTFC (<em>Read The Fine Code</em>) experience, the <a href=https://elixir.bootlin.com/linux>Elixir Cross Referencer</a> will more often than not come in handy.</p><p>The <a href=https://en.wikipedia.org/wiki/2024_CrowdStrike-related_IT_outages>CrowdStrike incident</a> showed that a mistake in the development of a kernel-level EDR can have catastrophic repercussions. Even though, in the CrowdStrike case, the problem arose from a logic bug, a simple memory issue could lead to the same result. Therefore, it would be safer to develop our tool in a language that gives more guarantees about the correctness of our program than C. For that, Rust is a good candidate.</p><p>Luckily for us, recently (around 2020) a new interface to develop kernel modules is being worked on by the <a href=https://rust-for-linux.com/>Rust for Linux</a> project. The main goal of this interface is to be able to develop Linux kernel modules in fully safe and idiomatic Rust. We will discuss this new kernel interface a bit more in the second part of this article.</p><h2 id=tools-provided-by-the-kernel>Tools provided by the kernel</h2><h3 id=data-analysis>Data analysis</h3><p>When running code in the kernel, we gain access to the structures of all subsystems present. This is particularly useful to monitor the state of the kernel and detect abnormal states.</p><h3 id=tracing>Tracing</h3><p>Another useful tool the kernel gives us access to is tracing APIs. Concretely, a tracing API lets you place callbacks, called probes, at certain points in the kernel that take as argument a context. These probes will then be called when those points are reached.</p><p>The Linux kernel offers a lot of tracing APIs (a full documentation can be found <a href=https://docs.kernel.org/trace/index.html>here</a>). Let&rsquo;s do a quick review of the most generic and common ones to understand their use-cases:</p><ul><li><strong><a href=https://docs.kernel.org/trace/tracepoints.html>Tracepoint</a></strong>: In this API, the places we can probe are statically defined. This has the advantage of a really low overhead, and we can also control the passed context (since it is defined by the developer who put the tracepoint). However, the probing points are limited.</li><li><strong><a href=https://docs.kernel.org/trace/fprobe.html>Fprobe</a></strong>: This API allows us to place probes on almost every function of the kernel, at entry and return. The passed context is the register trace at the entry and exit of the function.</li><li><strong><a href=https://docs.kernel.org/trace/kprobes.html>Kprobe</a></strong>: This one lets us probe any address of the kernel (not only the beginning or return of functions). As with <strong>fprobe</strong>, the context passed is the register trace at the probed point. However, it works by putting breakpoints at the probed point, so the overhead is quite high.</li><li><strong><a href=https://docs.kernel.org/trace/uprobetracer.html>Uprobe</a></strong>: This one is quite different from the others because it allows us to put breakpoints on any executable in the filesystem, which makes it the only tracing utility to be able to probe user space programs from the kernel. The context passed is also the register trace.</li></ul><p>To monitor the kernel for security purposes, the <strong>fprobe</strong> API is a reasonable choice as it gives a lot of freedom with a lesser overhead than <code>kprobe</code>, and probing start and exit of functions is sufficient for our use case. Hence, this is the API that I used in my tool.</p><blockquote><p>For security monitoring purposes, the <strong>uprobe</strong> API is also really interesting, however I focused mainly on the detection of kernel rootkits. Furthermore, the kernel-side <strong>uprobe</strong> API is neither straightforward to use nor well-documented.</p></blockquote><p>Now that we have all the available tools and a defined target, let&rsquo;s see how we can detect it.</p><h1 id=detecting-lkm-rootkits>Detecting LKM rootkits</h1><p>To accomplish this, the approach I chose was to analyze their inner workings and deduce checks to implement. To do that, we need some samples to work with:</p><ul><li><a href=https://github.com/f0rb1dd3n/Reptile>Reptile</a></li><li><a href=https://github.com/carloslack/KoviD>KoviD</a></li><li><a href=https://github.com/reveng007/reveng_rtkit>reveng_rtkit</a></li><li><a href=https://github.com/m0nad/Diamorphine>Diamorphine</a></li></ul><p>However, working on a recent Linux version (6.12) due to using Rust, only the first two rootkits were compatible and could be leveraged to assess the effectiveness of our tool.</p><h2 id=registration>Registration</h2><p>On Linux, kernel-level rootkits are subject to the same constraints as our tool if they want their code to be executed in the kernel, and remain persistent: they have to use the <strong>LKM</strong> interface.
More specifically, this means that their only method of loading code into the kernel is through the <code>init_module</code> syscall family (more commonly used through the <code>insmod</code> or <code>modprobe</code> commands)."</p><blockquote><p>This statement wasn&rsquo;t always true: before the <code>/dev/kmem</code> interface was removed, one could load a kernel module using this device file. However, this interface has been deactivated by default as of Linux 2.6.26 and permanently removed since 2021 (<a href=https://lwn.net/Articles/851531/>source</a>).</p></blockquote><p>Therefore, we can easily monitor the loading of every kernel module and potential rootkit, dump their name, analyze their executable, and calculate a hash of it. I did it by probing the <a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2514><code>do_init_module</code></a> function which is called by all the <code>init_module</code> syscall types.</p><p>This probe successfully detects the installation of our two kernel rootkit samples, but their hash can be effortlessly changed, which makes this test easy to bypass. Furthermore, this check will detect all module loadings indifferently.</p><h2 id=registration-structures>Registration structures</h2><p>We saw that the loading of a kernel module, by itself, is not enough to determine whether it is malicious.</p><p>If we read further what the <a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2854>loading routine</a> of an LKM does, we can roughly summarize it as the following steps:</p><ol><li><a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2245><strong>Allocate memory</strong></a> for the module&rsquo;s text and data</li><li><strong>Register the module</strong> in three different structures:<ul><li><a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2730><code>mod_list</code></a>: a linked list used notably by <code>lsmod</code> to list the current loaded LKMs</li><li><a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2731><code>mod_tree</code></a>: an RB tree used for address-to-module correspondence</li><li><a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2561><code>mkobj</code></a>: used to make LKMs appear in the <code>/sys</code> virtual filesystem</li></ul></li><li><a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2543><strong>Jump to the init function</strong></a> of the module</li></ol><p>The registering part is what allows us to list modules using <code>lsmod</code> for example. Hence, kernel rootkits will often seek to remove themselves from these quite bothersome structures.</p><p>However, we can observe that several open-source examples of rootkits fail to do so completely, as they often forget one structure to remove themselves from:</p><ul><li><code>Reptile</code> doesn&rsquo;t remove itself from the <code>mkobj</code> structure</li><li><code>Diamorphine</code> removes itself only from the <code>mod_list</code> structure</li></ul><p>What we can do is <strong>verify the consistency of these registration structures</strong>, which allows us to detect <code>Reptile</code>.</p><h2 id=brute-forcing-the-module-address-space>Brute-forcing the module address space</h2><p>What if a rootkit successfully removes itself from all these structures? That is, for instance, what the <a href=https://github.com/carloslack/KoviD>KoviD</a> rootkit achieves.</p><p>A solution was proposed in a 2024 <a href=https://phrack.org/issues/71/12#article>Phrack article</a>. The idea is based on what happens in the <strong>allocating memory</strong> step. If we read further the <a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/module/main.c#L2245>code of this step</a> (and look a bit into the ELF organization of an LKM), we can draw the following diagram:</p><p><a href=/posts/img/LKM-rootkit-rust-detection/bruteforce_module.png target=_blank><img src=/posts/img/LKM-rootkit-rust-detection/bruteforce_module.png alt="organization of the kernel LKM address range"></a></p><p>The kernel allocates memory for the LKMs in a specific address range (<a href=https://docs.kernel.org/arch/x86/x86_64/mm.html#complete-virtual-memory-map-with-5-level-page-tables>source</a>) and, for each LKM, it places the <code>.text</code> section, followed by the <code>.data</code> section, and finally it appends a structure of type <a href=https://elixir.bootlin.com/linux/v6.12/source/include/linux/module.h#L408><code>struct module</code></a> that describes the LKM.</p><p>This structure is particularly interesting because some of its fields have known valid ranges, namely:</p><ul><li><code>state</code>: an enum between 0 and 3</li><li><code>name</code>: a null-terminated, non-empty string of 56 characters</li><li><code>init</code> and <code>exit</code>: pointers into the LKM address range or null</li><li><code>core_layout.size</code> (size of the <code>.text</code> allocation): a non-zero multiple of <code>PAGE_SIZE</code></li></ul><p>Using this information, we can iterate through the LKM address range and try to match each allocated and aligned memory address with a <code>struct module</code> using the criteria we defined above. This gives us a way to find all the LKM structures. If we verify that each found LKM is correctly registered in the structures, we can detect suspicious modules.</p><p>This check allows our tool to detect both <code>Reptile</code> and <code>KoviD</code>.</p><h2 id=detection-using-kallsyms-api-calls>Detection using <code>kallsyms</code> API calls</h2><p>Once a kernel rootkit is successfully loaded, it will try to gain access to some structures in the kernel to tamper with. But there is a small problem with that: when developing an LKM, you only have access to the exported symbols (those exported using the <code>EXPORT_SYMBOL</code> family of macros), and most of the interesting symbols for kernel rootkits are not exported.</p><p>A solution to this problem is to use the <a href=https://elixir.bootlin.com/linux/v6.12/source/kernel/kallsyms.c#L402><code>kallsyms_lookup_name</code></a> function, which allows searching for the address of a given symbol.</p><p>We can observe that this function is not used a lot throughout the kernel source, and never used in a kernel module.</p><p>Plus, we can observe some common symbols that are used by rootkits, for instance:</p><ul><li><code>mod_tree_remove</code> which allows you to remove yourself from the <code>mod_tree</code> structure;</li><li>some syscalls, such as <code>__x64_sys_getdents64</code>, which lets you list files in a directory.</li></ul><p>Using this information and the calling address the <code>fprobe</code> API gives us access to, we can create a detection rule: if <code>kallsyms_lookup_name</code> is called by a module (i.e. the calling address is in the kernel&rsquo;s module address range), this is a suspicious usage (and even more so if the looked up symbol is commonly used by rootkits).</p><h3 id=indirect-calling>Indirect calling</h3><p>There is actually a problem with the previous technique: since 2020, <a href=https://lwn.net/Articles/813350/><code>kallsyms_lookup_name</code> is not exported anymore</a>, and thus kernel rootkits cannot rely on it anymore.</p><p>To overcome this problem, a new technique to find addresses of symbols appeared among Linux kernel rootkits: if we read the <a href=https://docs.kernel.org/trace/kprobes.html#api-reference><code>kprobe</code> API documentation</a>, we see that we can probe a point in the kernel by only indicating the symbol name, and the registering function will give us the address of the point probed.</p><p>In fact, if we read how <a href=https://elixir.bootlin.com/linux/v6.12-rc4/source/kernel/kprobes.c#L70><code>kprobe</code> implements address resolution</a>, we can see that it relies on the <code>kallsyms_lookup_name</code> function behind the scene. So, good news for us: we can keep the same probe to detect symbol resolution, because it&rsquo;s still the same function that is called underneath.</p><p>However, using this technique, the calling address of the function is in the kernel core. The module&rsquo;s function call happens several calls prior to this point, so we need to climb up the stack and look at each calling addresses. Luckily for us, the kernel exports an <a href=https://elixir.bootlin.com/linux/v6.12-rc4/source/kernel/stacktrace.c#L260>API for unwinding the kernel stack</a>, which we can leverage to check whether the stack trace contains an LKM address.</p><p>This check allows us to detect <code>Reptile</code> during its initialization phase.</p><blockquote><p>Can <code>kallsyms_lookup_name</code> be used by other code than LKMs?</p><p>Its main usage lies <a href=https://elixir.bootlin.com/linux/v6.12/A/ident/kallsyms_lookup_name>within the probing APIs</a>.
Something I didn&rsquo;t mention was that all the probing APIs I presented earlier have a user space counterpart. This counterpart has reduced capacity (you can&rsquo;t register any callback you want) and is mainly useful for debugging or performance profiling. This user space interface is managed by core kernel code.</p></blockquote><h2 id=inline-hooks-detection>Inline hooks detection</h2><p>In order to exhibit actual capabilities (other than hiding itself), a rootkit needs at some point to modify the way the kernel behaves. The most common current solution is to place probes in the kernel and modify the passed context. To achieve this, there are two options.</p><h3 id=1-use-a-kernel-probing-api>1. Use a kernel probing API</h3><p>Kernel probing APIs can be used to tamper with the state of the kernel at specific points (for example, by modifying the function parameters). This is easy to implement because the kernel provides all the necessary tools to do so.</p><p>However, this also means that all the probed points are managed by the kernel, and therefore, the kernel registers them somewhere accessible by every module — and even in some user space debug files.</p><p>The <a href=https://docs.kernel.org/trace/ftrace.html#the-file-system><code>enabled_functions</code> debug file</a>, for instance, shows all the functions probed in the kernel. We can see in the following example how <code>call_usermodehelper</code> is probed:</p><pre tabindex=0><code>call_usermodehelper (1) R         	tramp: 0xffffffffa0214000 (fprobe_handler+0x0/0x1c0) -&gt;ftrace_ops_assist_func+0x0/0xe0
</code></pre><p>This is what <code>KoviD</code> does: therefore, monitoring this debug file allows us to detect it.</p><h3 id=2-use-a-custom-probing-framework-often-called-hooking-framework>2. Use a custom probing framework (often called hooking framework)</h3><p>This is a bit more difficult to put in practice. There are a few open-source tools for Linux kernel hooking (e.g. <a href=https://github.com/milabs/khook>KHOOK</a>) already, although you could also roll your own hooking framework.</p><hr><p>But in either of these two cases, placing probes in the kernel implies modifying its text. Therefore, we can perform integrity checks on the kernel&rsquo;s text in multiple manners:</p><ul><li>Hash check for a simple yes/no response</li><li>Full byte-per-byte comparison for more information (which functions were hooked, where is the hook placed)</li></ul><p>These integrity checks allow us to find <code>Reptile</code> and <code>KoviD</code>, but only if they were installed after our tool started.</p><h3 id=finding-inline-hooks-installed-before-our-tool-is-started>Finding inline hooks installed before our tool is started</h3><p>To be able to detect inline hooks even when they are installed before us, we can note that probing is performed by placing either a JUMP or an INT3 instruction at the beginning of a function, which is not something you would normally find there.</p><p>We can iterate through all the text symbols of the kernel (i.e. all functions) and check the first opcode. The kernel has a handy function for that: <a href=https://elixir.bootlin.com/linux/v6.12-rc4/source/kernel/kallsyms.c#L250><code>kallsyms_on_each_symbol</code></a>. However, this function doesn&rsquo;t give us access to the section information of the symbol. Therefore, we chose to reimplement our own symbol iterating function in Rust to get access to the section information.</p><p>Once we do that, we can verify that each function hasn&rsquo;t been hooked by checking if their first opcode is not a JUMP, with the help of the <a href=https://elixir.bootlin.com/linux/v6.12/source/arch/x86/include/asm/insn.h#L1>in-kernel disassembler</a>.</p><blockquote><p>Why not also check for breakpoint instructions as some hooking techniques (e.g. <code>Kprobe</code>) use these?</p><p>The main reason is that while implementing this method, I discovered that breakpoint instructions were legitimately placed at the start of some functions, more specifically functions annotated with <code>__init</code> or <code>__exit</code>.
I suppose this allows to implement unloading of these functions, although I haven&rsquo;t dug any deeper.</p></blockquote><p>This check allows us to find <code>Reptile</code>, which leverages <code>KHOOK</code> to place JUMP instructions at the beginning of hooked functions.</p><blockquote><p>Another technique which was really common consisted in modifying function pointers in various kernel structures. This technique had the advantage of being easy to implement and more discreet.</p><p>Most of the time, the target structure was <code>sys_call_table</code> (the table for all the syscall handler function pointers), but since Linux 6.9, the <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=1e3ad78334a69b36e107232e337f9d693dcc9df2">syscall handling routine has been modified</a>, and it is now done with a <a href=https://elixir.bootlin.com/linux/v6.12/source/arch/x86/entry/syscall_64.c#L30>switch statement</a> (written in the most C-esque way possible).</p><p>It is still possible to tamper with other structures, but I have not found an open-source kernel rootkit that works only by modifying function pointers on a modern Linux kernel (so without <code>sys_call_table</code>).
I also tried to do it myself unsuccessfully.</p><p>However, my tool still watches for rootkits that may tamper with <code>sys_call_table</code> because while it is not used anymore, it still exists for legacy purposes.</p></blockquote><h1 id=developing-a-rust-kernel-module-a-review>Developing a Rust kernel module: a review</h1><p>The entire tool has been developed in Rust in the Linux 6.12 kernel. As the <strong>Rust for Linux</strong> project is still in its early stages, we give a review of the general experience of developing in the Linux kernel using Rust.</p><h2 id=the-goal-of-rust-for-linux>The goal of <em>Rust for Linux</em></h2><p>The main goal of the <strong>Rust for Linux</strong> project is to propose a <strong>fully safe and idiomatic Rust driver API</strong> in the kernel. In other words, the objective is to allow anyone to develop Linux kernel drivers (LKMs) in Rust, just like developing a Rust userspace application<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, so it doesn&rsquo;t involve rewriting core kernel code.</p><h2 id=the-environment>The environment</h2><p>To fulfill its goal, the main effort of the project is focused on wrapping Linux&rsquo;s C driver API in Rust such that the resulting API is safe and idiomatic, creating what is known as a Rust <strong>abstraction</strong>.</p><p><a href=/posts/img/LKM-rootkit-rust-detection/rust_for_linux.png target=_blank><img src=/posts/img/LKM-rootkit-rust-detection/rust_for_linux.png alt="Organization of the writing of Rust abstraction"></a></p><ol><li>The kernel&rsquo;s C headers are transformed into Rust <code>unsafe</code> function declarations and structure definitions. This step is automatically done by the <code>bindgen</code> tool.</li><li>Unsafe functions are wrapped by abstractions in the <a href=https://rust.docs.kernel.org/next/kernel/><em>kernel</em> Rust crate</a>.</li><li>The driver&rsquo;s code is written by calling safe functions from the <em>kernel</em> crate. Although developers have access to the bindings generated by <code>bindgen</code>, they shouldn&rsquo;t use them and instead merge the Rust abstractions they are missing in the <em>kernel</em> crate such that no FFI calls is directly made from the driver.</li></ol><h2 id=state-of-the-rust-for-linux-project-as-of-february-2025>State of the <em>Rust for Linux</em> project (as of February 2025)</h2><p>In practice, the <em>Rust for Linux</em> project is still relatively new and takes time to progress (mainly because a lot of attention is given to designing abstractions). Therefore, as of now and for the foreseeable future, the experience of developing in Rust in the kernel involves writing many abstractions yourself, which is a tedious process. For example, for my tool, I notably had to implement abstractions for:</p><ul><li>the <code>fprobe</code> API;</li><li>the <code>insn</code> API (disassembler);</li><li>the module management API.</li></ul><p>Though, during the course of my six-month internship, the project has made significant progress and the number of available abstractions has almost doubled, with major ones being merged:</p><ul><li><code>miscdevice</code>: to create generic device files for driver ↔ user space communication</li><li><code>PCI</code> and <code>platform</code> bus APIs: to create drivers for hardware relying on these buses</li><li><code>io</code> API: to communicate with hardware</li></ul><p>In consequence, a few drivers have been merged: two <code>PHY</code> device drivers, and the beginning of a new driver for NVIDIA GPUs (<em>Nova</em>).</p><blockquote><p>When talking to people about <em>Rust for Linux</em>, some seem to think that the project is in bad shape, and some believe it will die (for example because of resignations). Here is my perspective on the matter.</p><p>Overall, the project is doing great. First, it has the <a href=https://lore.kernel.org/rust-for-linux/2024122031-outfit-mop-86d0@gregkh/>backing of Greg K-H</a>, the person responsible for everything driver-related in the Linux kernel, which makes it difficult for any individual to completely block its progress.</p><p>In fact, many interactions with C kernel maintainers have been really positive. They often show interest in Rust and seem to appreciate that the <em>Rust for Linux</em> project is working on abstractions for their subsystems (see, for example, the questions from <code>mm</code> subsystem maintainer Lorenzo Stoakes in <a href=https://lore.kernel.org/rust-for-linux/0c6f4dbb-ff09-439c-b736-35568c1450cc@lucifer.local/T/#u>this thread</a>).</p><p>Furthermore, some major abstractions have been merged. The <code>PCI</code> and <code>platform</code> abstractions, for instance, are important milestones. We are also seeing RFCs for drivers appearing on the <em>Rust for Linux</em> mailing list, indicating that the project is starting to fulfill its goal! Unfortunately, these successes are rarely talked about.</p></blockquote><h2 id=is-writing-drivers-in-rust-worth-it>Is writing drivers in Rust worth it?</h2><p>While adding Rust to the kernel is a lot of work, I found that there were multiple benefits.</p><h3 id=typing-system>Typing system</h3><p>The main advantage of Rust is its type system. It is one of the few languages that will give you access to such a complete type system (be it structured types or lifetime expressions) — and at the same time, if you believe you do know better than the compiler, it allows you to bypass it explicitly by encapsulating the code in an <code>unsafe</code> block.</p><p>For example, we can compare a structure <code>Foo</code> with a field of type <code>struct Bar</code> protected by a mutex, in both C and Rust:</p><h4 id=c>C</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C data-lang=C><span style=display:flex><span><span style=color:#66d9ef>struct</span> Foo {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>struct</span> Bar bar;
</span></span><span style=display:flex><span>    mutex bar_mutex;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h4 id=rust>Rust</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Rust data-lang=Rust><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Foo</span> {
</span></span><span style=display:flex><span>    bar: <span style=color:#a6e22e>Mutex</span><span style=color:#f92672>&lt;</span>Bar<span style=color:#f92672>&gt;</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Although in this example, is seems obvious that in the C version the mutex is related to the <code>bar</code> field, nothing really enforces it and prevents you from forgetting to take or release it. Even if it comes with documentation, the risk of having inconsistencies between the documentation and the actual code is still there.</p><p>Whereas in the Rust version, it is impossible (at least without <code>unsafe</code>) to access the <code>Bar</code> structure without taking the mutex — and the lifetime system guarantees you that the lock will be released automatically when you don&rsquo;t need it anymore.</p><p>This is a simple example featuring a structure and a single field, but many kernel structures have dozens of fields, and their synchronization requirements are rarely documented<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, which makes implementing them in Rust even more beneficial. Rust&rsquo;s benefits also extend to functions, making the API more explicit without requiring additional documentation.</p><h3 id=safety>Safety</h3><p>I believe the safety argument is secondary for two reasons: first, wrapping C APIs in Rust doesn&rsquo;t make them any safer, and second, Rust&rsquo;s safety argument primarily comes from its type system because, as we saw, it enforces a good usage of those APIs.</p><p>Since Rust excels at enforcing requirements at compile time (be it lifetime or usage requirements), writing your driver in Rust almost guarantees that you won&rsquo;t introduce issues by misusing the kernel API (which is a common source of bugs and vulnerabilities).</p><h3 id=linting>Linting</h3><p>Because Rust is more explicit than C, it also enables better linting, which is used in the kernel:</p><ul><li>All unsafe code must be justified with a <code>SAFETY</code> comment indicating how all the safety conditions are upheld.</li><li>Public APIs (marked with the <code>pub</code> keyword) must include documentation written in the <code>rustdoc</code> format. As a result, the kernel&rsquo;s crate documentation follows the same format as any other Rust crate, making it easier to understand for developrs coming from a Rust background.</li></ul><hr><blockquote><p>And if you&rsquo;re still not convinced, you can go take a look at the <a href=https://elixir.bootlin.com/linux/v6.12-rc4/source/kernel/module/main.c#L3011>error handling code of <code>load_module</code></a> and remember that in Rust, all the failure checks and cleaning steps could be replaced by simply appending a <code>?</code> on each function call.</p></blockquote><h1 id=conclusion>Conclusion</h1><p>In this post, we walked through the development of a malware detection tool in Rust (which you can find on <a href=https://github.com/thalium/rkchk>Github</a>) and we explored a few rootkit techniques.</p><p>Since monitoring capabilities of LKMs are not a primary focus of the <em>Rust for Linux</em> project, many abstractions had to be reimplemented, but I still enjoyed writing my tool in Rust. I found that the Rust documentation and abstractions are way easier to work with than their C counterparts.</p><p>Overall, I believe the goal of making driver development more accessible with the introduction of Rust will be achieved.</p><p>Although adding a new language in the kernel involves significant work and may complicate the maintenance of the C API, the long-term benefits, such as simplifying driver development and accelerating code reviews for maintainers, will largely offset these challenges. They won&rsquo;t need to correct API usage, or check if resources are properly freed for instance, and sections requiring extra care (such as <code>unsafe</code> blocks) will be explicitly marked.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Of course the way of programming in the kernel is different from the user space and Rust for Linux is no exception.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>I&rsquo;m not criticizing the C code; if it&rsquo;s written this way, there&rsquo;s probably a good reason for it.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><div class=post-footer-data><div class=tags><div class=tag><a href=/tags/linux>#Linux</a></div><div class=tag><a href=/tags/kernel>#Kernel</a></div><div class=tag><a href=/tags/malware>#Malware</a></div><div class=tag><a href=/tags/rust>#Rust</a></div></div><span class=date>2025-03-12
<span class=author>by
Antoine Doglioli</span></span></div></footer></article><footer><div class=social-links-footer><a href=mailto:contact@thalium.re><div class=social-link>Email</div></a><a href=https://github.com/thalium target=_blank><div class=social-link>Github</div></a><a href=https://twitter.com/thalium_team target=_blank><div class=social-link>Twitter</div></a></div><div class=copyright>Copyright (c) 2025, all rights reserved.</div><div class=poweredby>Powered by <a href=https://gohugo.io/>Hugo</a>.</div></footer></div></body></html>